{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15a0340-f670-4c0a-a581-9f2223d0cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91da1ac-478e-4f45-9863-968ddcd44692",
   "metadata": {},
   "source": [
    "# Uber Pickups Conversion (csv -> pkl aka dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d50da8-6380-4a9c-be26-2db7adcfa63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uber_conv():\n",
    "    directory = \"archive\"\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and filename.endswith('.csv') and not os.path.isfile(f\"pkl/{filename}.pkl\"):\n",
    "            print(f\"Reading {f}\")\n",
    "            try:\n",
    "                df = pd.read_csv(f, encoding='latin1')\n",
    "                pkl_file = f\"pkl/{filename}.pkl\"\n",
    "                print(f\"Converting {f} to {pkl_file}\")\n",
    "                df.to_pickle(pkl_file)\n",
    "                # print(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {f}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd58761-189d-4701-ac39-0d0dc2ba1e2d",
   "metadata": {},
   "source": [
    "# T-Drive Conversion (txt -> csv -> pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2098c5f-d5de-4055-b704-a5f8c5b05e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tdrive_conv():\n",
    "    directory = \"release/taxi_log_2008_by_id\"\n",
    "    column_names = [\"taxi id\", \"date time\", \"longitude\", \"latitude\"]\n",
    "    if not os.path.isfile(\"release/taxi_log_2008_by_id.csv\"):\n",
    "        with open(\"release/taxi_log_2008_by_id.csv\", 'w', newline='') as target:\n",
    "            writer = csv.DictWriter(target, fieldnames=column_names)\n",
    "            writer.writeheader()\n",
    "            for path in glob.glob(f\"{directory}/*.txt\"):\n",
    "                with open(path, newline='') as source:\n",
    "                    reader = csv.DictReader(source, delimiter=',', fieldnames=column_names)\n",
    "                    writer.writerows(reader)\n",
    "\n",
    "    if not os.path.isfile(\"release/taxi_log_2008_by_id.pkl\"):\n",
    "        df = pd.read_csv(\"release/taxi_log_2008_by_id.csv\", encoding=\"latin1\")\n",
    "        pkl_file = \"taxi_log_2008_by_id.pkl\"\n",
    "        print(f\"Converting to {pkl_file}\")\n",
    "        df.to_pickle(\"release/\" + pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f592f05-e27e-4d94-9e61-13682b8dbdc6",
   "metadata": {},
   "source": [
    "# Uber Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81eedcbe-7aae-4daa-9ebd-64aab962138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uber_combine():\n",
    "    if os.path.isfile(\"archive/uber-raw-combined.csv\"):\n",
    "        return\n",
    "    directory = \"archive\"\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\") and \"uber-raw-data\" in filename:\n",
    "            df = pd.read_csv(os.path.join(directory, filename))\n",
    "            df_list.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    combined_df.to_csv('archive/uber-raw-combined.csv', index=False)\n",
    "    \n",
    "    print(\"CSV files have been combined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "633edd23-9674-4520-842d-962ad5d17bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting T-drive dataset: txt -> csv -> pkl\n",
      "Combining all uber-raw-data csvs together\n",
      "Converting Uber dataset: csv -> pkl\n",
      "Reading archive\\uber-raw-combined.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raymo\\AppData\\Local\\Temp\\ipykernel_28488\\2926630387.py:8: DtypeWarning: Columns (0,3,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting archive\\uber-raw-combined.csv to pkl/uber-raw-combined.csv.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting T-drive dataset: txt -> csv -> pkl\")\n",
    "tdrive_conv()\n",
    "\n",
    "print(\"Combining all uber-raw-data csvs together\")\n",
    "uber_combine()\n",
    "\n",
    "print(\"Converting Uber dataset: csv -> pkl\")\n",
    "uber_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b815156-2a82-45b1-b002-a88678602cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
